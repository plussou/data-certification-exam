{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Sentiment Analysis of French Movie Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDsXJRI3Wfrv"
   },
   "source": [
    "### Objectives\n",
    "1. Text cleaning\n",
    "2. Text preprocessing for custom embedding Neural Network\n",
    "3. Train RNN model for sentiment analysis\n",
    "\n",
    "‚ö†Ô∏è This notebook will be your final deliverable. \n",
    "- Make sure it can run \"restart and run all\"\n",
    "- Delete useless code cells\n",
    "- Do not \"clear output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvwURl10Wmw1"
   },
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains 30,000 french reviews of movies, along with the binary class 1 (positive) or 0 (negative) score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8472,
     "status": "ok",
     "timestamp": 1615382505157,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -60
    },
    "id": "IufC0UUhxyGC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>√áa commence √† devenir √©nervant d'avoir l'impre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J'ai aim√© ce film, si il ressemble a un docume...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Une grosse merde ce haneke ce faire produire p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beau m√©lodrame magnifiquement photographi√©, \"V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A la poursuite du diamant vers est un film pro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29946</th>\n",
       "      <td>Le meilleur film de super-h√©ros derri√®re le ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29947</th>\n",
       "      <td>Un drame qui est d'une efficacit√© remarquable....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29948</th>\n",
       "      <td>Une daube hollywoodienne de plus, aucun int√©r√™...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29949</th>\n",
       "      <td>Et voil√† un nouveau biopic sur la star du X Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29950</th>\n",
       "      <td>Un film qui fait vieux, avec des acteurs pas t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29951 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  polarity\n",
       "0      √áa commence √† devenir √©nervant d'avoir l'impre...         0\n",
       "1      J'ai aim√© ce film, si il ressemble a un docume...         1\n",
       "2      Une grosse merde ce haneke ce faire produire p...         0\n",
       "3      Beau m√©lodrame magnifiquement photographi√©, \"V...         1\n",
       "4      A la poursuite du diamant vers est un film pro...         1\n",
       "...                                                  ...       ...\n",
       "29946  Le meilleur film de super-h√©ros derri√®re le ba...         1\n",
       "29947  Un drame qui est d'une efficacit√© remarquable....         1\n",
       "29948  Une daube hollywoodienne de plus, aucun int√©r√™...         0\n",
       "29949  Et voil√† un nouveau biopic sur la star du X Li...         0\n",
       "29950  Un film qui fait vieux, avec des acteurs pas t...         0\n",
       "\n",
       "[29951 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load the dataset for you\n",
    "data = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/movies.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8472,
     "status": "ok",
     "timestamp": 1615382505157,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -60
    },
    "id": "IufC0UUhxyGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    15051\n",
      "0    14900\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We create features\n",
    "y = data.polarity\n",
    "X = data.review\n",
    "\n",
    "# We analyse class balance\n",
    "print(pd.value_counts(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1615383356787,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -60
    },
    "id": "yzIpNmSg0XV4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity: 0 \n",
      "\n",
      "√áa commence √† devenir √©nervant d'avoir l'impression de voir et revoir le m√™me genre de film √† savoir : la com√©die romantique, surement le genre le plus prolifique de le production fran√ßaise actuelle. Le probl√®me c'est que l'on a souvent affaire √† des niaiseries de faible niveau comme celui ci. Avec un scenario ultra balis√© et conventionnel, c'est √† se demander comment √ßa peut passer les portes d'un producteur. Bref cette sempiternel histoire d'un homme mentant au nom de l'amour pour reconqu√©rir une femme et qui √† la fin se prend son mensonge en pleine figure est d'une originalit√© affligeante, et ce n'est pas la pr√©sence au casting de l'ex miss m√©t√©o Charlotte Le Bon qui r√™ve surement d'avoir la m√™me carri√®re que Louise Bourgoin qui change la donne.\n"
     ]
    }
   ],
   "source": [
    "# We check various reviews\n",
    "print(f'polarity: {y[0]} \\n')\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clean Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì We need to give a _quick & dirty_ cleaning to all the sentences in the dataset. Create a variable `X_clean` of similar shape, but with the following cleaning:\n",
    "- Replace french accents by their non-accentuated equivalent using the [unidecode.unidecode()](https://pypi.org/project/Unidecode/) method\n",
    "- Reduce all uppercases to lowercases\n",
    "- Remove any characters outside of a-z, for instance using `string.isalpha()`\n",
    "\n",
    "üòå You will be given the solution `X_clean` in the next question to make sure you can complete the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "def remove_ponctuation(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text.strip() \n",
    "\n",
    "def lower_and_clean(input_str):\n",
    "    return u\" \".join([w.lower() for w in input_str.split() if w.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beau melodrame magnifiquement photographie, \"Veronika Voss\" est aussi un bel hommage a l\\'Hollywood d\\'antan et au chef-d\\'oeuvre de Billy Wilder, \"Sunset boulevard\". Ce qui frappe toujours, 35 ans apres sa realisation, c\\'est la beaute de la mise en scene de Fassbinder, les mouvements de camera toujours a propos et une direction d\\'acteurs d\\'une grande precision. Encore une fois, le talent proteiforme du cineaste s\\'exprime magnifiquement dans une veine melodramatique, a priori eloignee de l\\'univers creatif de ses premieres annees, qu\\'un socle theatral semble rattacher indeniablement.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = remove_accents(X[3])\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beau melodrame magnifiquement est aussi un bel hommage a et au de billy ce qui frappe ans apres sa la beaute de la mise en scene de les mouvements de camera toujours a propos et une direction grande encore une le talent proteiforme du cineaste magnifiquement dans une veine a priori eloignee de creatif de ses premieres socle theatral semble rattacher'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = lower_and_clean(r1)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X.apply(remove_accents)\n",
    "X_clean = X_clean.apply(remove_ponctuation)\n",
    "X_clean = X_clean.apply(lower_and_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca commence a devenir enervant davoir limpression de voir et revoir le meme genre de film a savoir la comedie romantique surement le genre le plus prolifique de le production francaise actuelle le probleme cest que lon a souvent affaire a des niaiseries de faible niveau comme celui ci avec un scenario ultra balise et conventionnel cest a se demander comment ca peut passer les portes dun producteur bref cette sempiternel histoire dun homme mentant au nom de lamour pour reconquerir une femme et qui a la fin se prend son mensonge en pleine figure est dune originalite affligeante et ce nest pas la presence au casting de lex miss meteo charlotte le bon qui reve surement davoir la meme carriere que louise bourgoin qui change la donne'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29951,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29951,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('C14',\n",
    "    shape = X_clean.shape,\n",
    "    first_sentence = X_clean[0]\n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have clean sentences, we need to convert each one into a list of integers of fixed size\n",
    "- For example, the sentence: `\"this was good\"` should become something like `array([1, 3, 18, 0, 0, 0, ...0], dtype=int32)` where each integer match to a each _unique_ word in your corpus of sentences.\n",
    "\n",
    "‚ùì Create a numpy ndarray `X_input` of shape (29951, 100) that will be the direct input to your Neutral Network. \n",
    "\n",
    "- 29951 represents the number of reviews in the dataset `X_clean`\n",
    "- 100 represents the maximum number of words to keep for each movie review.\n",
    "- It must contain only numerical values, without any `NaN`\n",
    "- In the process, compute and save the number of _unique_ words in your cleaned corpus under `vocab_size` variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ First, you **must** start back from the clean solution below (14Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ca commence a devenir enervant de voir et revoir le meme genre de film a savoir la comedie romantique surement le genre le plus prolifique de le production francaise actuelle le probleme que a souvent affaire a des niaiseries de faible niveau comme celui ci avec un scenario ultra balise et conventionnel a se demander comment ca peut passer les portes producteur bref cette sempiternel histoire homme mentant au nom de pour reconquerir une femme et qui a la fin se prend son mensonge en pleine figure est originalite affligeante et ce pas la presence au casting de miss meteo charlotte le bon qui reve surement la meme carriere que louise bourgoin qui change la donne',\n",
       "       'aime ce film si il ressemble a un documentaire voit a la tete pendant le film je me demandais vont leur arriver par la suite',\n",
       "       'une grosse merde ce haneke ce faire produire par des francais et pares dire non aux cesar parce que moins classe que les oscars ce que je comprends parce que les cesars vraiment du cirque mais son attitude est bien plus elitiste que ces films de merde',\n",
       "       ..., 'une daube hollywoodienne de plus aucun interet vraiment',\n",
       "       'et voila un nouveau biopic sur la star du x linda lovelace qui a defraye la chronique dans les annees apres avoir revolutionnee le film erotique avec le culte gorge profonde lovelace subit les foudres mari violent qui ne la voit que comme un et un objet du desir et tente a cinematographique et pornographique en ecrivant ses memoires icone du feminisme declencheuse de sexuelle lovelace eut une fin tragique en le film est tres loin de lui rendre justice tout il survole trop rapidement les evenements on comprend que en reaction a des parents bigots que lovelace integra le milieu du mais tout cela est tres maladroitement amene le montage privilegie exagerement le personnage peu interessant du mari peter sarksgaard en roue libre quant au potentiel coquin il en provoquant involontairement le rire ou la gene amanda seyfried a certainement le physique de et pas peu mais elle est tres jeune pour le role et son personnage reste fadasse tout a fait dispensable',\n",
       "       'un film qui fait vieux avec des acteurs pas tout jeunes pour une histoire des annees la french est un produit hors qui joue sur tous les tons la po au se vintage franchement pas affriolant comme un dimanche chez drucker qui enqueterait sur le milieu marseillais dujardin pas tres bon mais lellouche est un peu plus credible a porter au credit du film de tres bons seconds roles un caractere documentaire instructif pour les jeunes generations une jolie photographie de marseille a decharge le reste engonce dans sa mollesse intrinseque le film parvient a susciter plus curieux que le degout ce qui deja pas si mal aux articles'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/movies_X_clean.csv\")['review']\n",
    "X_clean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=100, ngram_range=(2, 2))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range = (2,2), max_features=100)\n",
    "tf_idf_vectorizer.fit(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = tf_idf_vectorizer.transform(X_clean)\n",
    "X_input = X_input.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29951, 100)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('C1415',\n",
    "    type_X = type(X_input),\n",
    "    shape = X_input.shape, \n",
    "    input_1 = X_input[1], \n",
    ")\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjM5UP5ZMbY_"
   },
   "source": [
    "# 3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìCreate and fit a Neural Netork that takes `X_input` and `y` as input, to binary classify each sentence's sentiment\n",
    "\n",
    "- You cannot use transfer learning or other pre-existing Word2Vec models\n",
    "- You must use a \"recurrent\" architecture to _capture_ a notion of order in the sentences' words\n",
    "- The performance metrics for this task is \"accuracy\"\n",
    "- Store your model in a variable `model` \n",
    "- Store the result your `model.fit()` in a variable `history`. \n",
    "- ‚ö†Ô∏è `history.history` must comprises a measure of the `val_accuracy` at each epoch.\n",
    "- You don't need to cross-validate your model\n",
    "\n",
    "üòå Don't worry, you will not be judged on your computer power: You should be able to reach accuracy significantly better than baseline in less than 3 minutes even without GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ But first, you **must** start back from the solution below (70Mo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/movies_X_input.csv'\n",
    "X_input = np.genfromtxt(url, delimiter=',', dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29951, 100)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 16, 17, 18, 10, 12, 10, 19, 20,  6, 10, 21, 22, 23, 10, 24, 25,\n",
       "        3, 26, 27,  3, 28, 29,  6, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "        8, 40,  3, 41, 42, 43,  1, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56,  6, 57, 58, 59, 60,  8, 61,  3, 15, 62, 41, 63, 64, 65,\n",
       "       66, 67, 68, 69, 70, 71,  8, 72, 73, 15, 74, 55, 75,  6, 76, 77, 78,\n",
       "       10, 79, 61, 80, 18, 15, 11, 81, 25, 82, 83, 61, 84, 15, 85],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29951,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54073"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(np.unique(X_input))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62379"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_input.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=80_000, output_dim=100))\n",
    "    model.add(layers.LSTM(10))\n",
    "    model.add(layers.Dense(5))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1311/1311 [==============================] - 94s 69ms/step - loss: 0.5905 - accuracy: 0.6584 - val_loss: 0.3447 - val_accuracy: 0.8760\n",
      "Epoch 2/10\n",
      "1311/1311 [==============================] - 83s 63ms/step - loss: 0.2870 - accuracy: 0.8928 - val_loss: 0.3134 - val_accuracy: 0.8882\n",
      "Epoch 3/10\n",
      "1311/1311 [==============================] - 83s 63ms/step - loss: 0.2178 - accuracy: 0.9218 - val_loss: 0.3471 - val_accuracy: 0.8663\n",
      "Epoch 4/10\n",
      "1311/1311 [==============================] - 80s 61ms/step - loss: 0.1953 - accuracy: 0.9322 - val_loss: 0.2753 - val_accuracy: 0.8933\n",
      "Epoch 5/10\n",
      "1311/1311 [==============================] - 81s 61ms/step - loss: 0.1748 - accuracy: 0.9371 - val_loss: 0.2782 - val_accuracy: 0.8964\n",
      "Epoch 6/10\n",
      "1311/1311 [==============================] - 83s 63ms/step - loss: 0.1640 - accuracy: 0.9458 - val_loss: 0.3413 - val_accuracy: 0.8739\n",
      "Epoch 7/10\n",
      "1311/1311 [==============================] - 79s 60ms/step - loss: 0.1341 - accuracy: 0.9560 - val_loss: 0.2955 - val_accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "1311/1311 [==============================] - 84s 64ms/step - loss: 0.1319 - accuracy: 0.9518 - val_loss: 0.3255 - val_accuracy: 0.8874\n",
      "Epoch 9/10\n",
      "1311/1311 [==============================] - 80s 61ms/step - loss: 0.1205 - accuracy: 0.9614 - val_loss: 0.3171 - val_accuracy: 0.8827\n",
      "Epoch 10/10\n",
      "1311/1311 [==============================] - 82s 63ms/step - loss: 0.1126 - accuracy: 0.9605 - val_loss: 0.3614 - val_accuracy: 0.8923\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_input, y, \n",
    "          epochs=10, \n",
    "          batch_size=16,\n",
    "          validation_split=0.3,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('C1517',\n",
    "                         history=history.history)\n",
    "result.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNt966tqZXM2p288pQsUAUV",
   "name": "certification_DL_NLP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "lewagon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
