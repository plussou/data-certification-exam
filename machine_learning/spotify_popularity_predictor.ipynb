{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Popularity Predictor (39%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this challenge is to create a model that predicts the popularity of a song based on its features.\n",
    "\n",
    "The dataset contains a list of tracks with the following characteristics:\n",
    "- `acousticness`: whether the track is acoustic\n",
    "- `danceability`: describes how suitable a track is for dancing\n",
    "- `duration_ms`: duration of the track in milliseconds\n",
    "- `energy`: represents a perceptual measure of intensity and activity\n",
    "- `explicit`: whether the track has explicit lyrics\n",
    "- `id`: id for the track\n",
    "- `instrumentalness`: predicts whether a track contains no vocals\n",
    "- `key`: the key the track is in\n",
    "- `liveness`: detects the presence of an audience in the recording\n",
    "- `loudness`: the overall loudness of a track in decibels\n",
    "- `mode`: modality of a track\n",
    "- `name`: name of the track\n",
    "- `popularity`: popularity of the track\n",
    "- `release_date`: release date\n",
    "- `speechiness`: detects the presence of spoken words in a track\n",
    "- `tempo`: overall estimated tempo of a track in beats per minute\n",
    "- `valence`: describes the musical positiveness conveyed by a track\n",
    "- `artist`: artist who performed the track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection\n",
    "\n",
    "üìù **Load the `spotify_popularity_train.csv` dataset from the provided URL**\n",
    "- Display the first few rows\n",
    "- Perform the basic cleaning operations (remove redundant lines, as well as those with missing values)\n",
    "- Store the result in a `DataFrame` named `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/certification_paris_2021Q1/spotify_popularity_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.654</td>\n",
       "      <td>0.499</td>\n",
       "      <td>219827</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0B6BeEUd6UwFlbsHMQKjob</td>\n",
       "      <td>0.00409</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>-16.435</td>\n",
       "      <td>1</td>\n",
       "      <td>Back in the Goodle Days</td>\n",
       "      <td>40</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>149.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>John Hartford</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  explicit  \\\n",
       "0         0.654         0.499       219827    0.19         0   \n",
       "\n",
       "                       id  instrumentalness  key  liveness  loudness  mode  \\\n",
       "0  0B6BeEUd6UwFlbsHMQKjob           0.00409    7    0.0898   -16.435     1   \n",
       "\n",
       "                      name  popularity release_date  speechiness   tempo  \\\n",
       "0  Back in the Goodle Days          40         1971       0.0454  149.46   \n",
       "\n",
       "   valence         artist  \n",
       "0     0.43  John Hartford  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52317 entries, 0 to 52316\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   acousticness      52317 non-null  float64\n",
      " 1   danceability      52317 non-null  float64\n",
      " 2   duration_ms       52317 non-null  int64  \n",
      " 3   energy            52317 non-null  float64\n",
      " 4   explicit          52317 non-null  int64  \n",
      " 5   id                52317 non-null  object \n",
      " 6   instrumentalness  52317 non-null  float64\n",
      " 7   key               52317 non-null  int64  \n",
      " 8   liveness          52317 non-null  float64\n",
      " 9   loudness          52317 non-null  float64\n",
      " 10  mode              52317 non-null  int64  \n",
      " 11  name              52317 non-null  object \n",
      " 12  popularity        52317 non-null  int64  \n",
      " 13  release_date      52317 non-null  object \n",
      " 14  speechiness       52317 non-null  float64\n",
      " 15  tempo             52317 non-null  float64\n",
      " 16  valence           52317 non-null  float64\n",
      " 17  artist            52313 non-null  object \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52313 entries, 0 to 52316\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   acousticness      52313 non-null  float64\n",
      " 1   danceability      52313 non-null  float64\n",
      " 2   duration_ms       52313 non-null  int64  \n",
      " 3   energy            52313 non-null  float64\n",
      " 4   explicit          52313 non-null  int64  \n",
      " 5   id                52313 non-null  object \n",
      " 6   instrumentalness  52313 non-null  float64\n",
      " 7   key               52313 non-null  int64  \n",
      " 8   liveness          52313 non-null  float64\n",
      " 9   loudness          52313 non-null  float64\n",
      " 10  mode              52313 non-null  int64  \n",
      " 11  name              52313 non-null  object \n",
      " 12  popularity        52313 non-null  int64  \n",
      " 13  release_date      52313 non-null  object \n",
      " 14  speechiness       52313 non-null  float64\n",
      " 15  tempo             52313 non-null  float64\n",
      " 16  valence           52313 non-null  float64\n",
      " 17  artist            52313 non-null  object \n",
      "dtypes: float64(9), int64(5), object(4)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"data_cleaning\",\n",
    "    shape=data.shape).write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
       "       'id', 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'name',\n",
       "       'popularity', 'release_date', 'speechiness', 'tempo', 'valence',\n",
       "       'artist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Which sklearn's scoring [metric](https://scikit-learn.org/stable/modules/model_evaluation.html) should we use if we want to:**\n",
    "- **Strongly penalize** largest errors\n",
    "- Measure errors **in the same unit** than `popularity` \n",
    "- Is better when greater (metric_good_model > metric_bad_model)\n",
    "\n",
    "üëâ Store its exact name as `string` in the variable `scoring` below\n",
    "\n",
    "üö® You must use this metric for the rest of the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'neg_root_mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Let's build a first simple linear model using only the numerical features in our dataset to start with**\n",
    "- Build `X_simple` keeping only numerical features\n",
    "- Build `y` your target containing the `popularity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple = data[['acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\\\n",
    "                 'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\\\n",
    "                 'speechiness', 'tempo', 'valence',]]\n",
    "y = data[['popularity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52313 entries, 0 to 52316\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   acousticness      52313 non-null  float64\n",
      " 1   danceability      52313 non-null  float64\n",
      " 2   duration_ms       52313 non-null  int64  \n",
      " 3   energy            52313 non-null  float64\n",
      " 4   explicit          52313 non-null  int64  \n",
      " 5   instrumentalness  52313 non-null  float64\n",
      " 6   key               52313 non-null  int64  \n",
      " 7   liveness          52313 non-null  float64\n",
      " 8   loudness          52313 non-null  float64\n",
      " 9   mode              52313 non-null  int64  \n",
      " 10  speechiness       52313 non-null  float64\n",
      " 11  tempo             52313 non-null  float64\n",
      " 12  valence           52313 non-null  float64\n",
      "dtypes: float64(9), int64(4)\n",
      "memory usage: 5.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_simple.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Create the 4 variables `X_train_simple` `y_train`, `X_test_simple`, `y_test` with a 50% split with random sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_simple, X_test_simple, y_train, y_test = train_test_split(X_simple,y,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Fit and evaluate a basic linear model (do not fine tune it) with this holdout method**\n",
    "- Store your model true performance in a float variable `score_simple_holdout`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preproc', StandardScaler()), ('model', LinearRegression())])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "preproc = StandardScaler()\n",
    "lin_model = LinearRegression()\n",
    "\n",
    "basic_model = Pipeline([('preproc',preproc),\n",
    "                        ('model',lin_model)\n",
    "                       ])\n",
    "\n",
    "basic_model.fit(X_train_simple,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mse(mse):\n",
    "    return math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.33817747072249"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = basic_model.predict(X_test_simple)\n",
    "score_simple_holdout = root_mse(mean_squared_error(y_test,y_pred))\n",
    "score_simple_holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Let's be sure our score is representative**: \n",
    "- 5-times cross validate a basic linear model on the whole numeric dataset (`X_simple`, `y`)\n",
    "- Do not fine tune your model\n",
    "- Store your mean performance in a variable `score_simple_cv_mean` as a `float`\n",
    "- Store the standard deviation of your performances in a float variable `score_simple_cv_std`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv = cross_validate(basic_model, X_simple, y, cv=5, scoring='neg_root_mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-18.43649885, -18.46079317, -18.37189603, -18.47472207,\n",
       "       -18.24571041])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_simple_cv_mean = - cv['test_score'].mean()\n",
    "score_simple_cv_std =  cv['test_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.397924106389315"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_simple_cv_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08388674341016651"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_simple_cv_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"simple_model\",\n",
    "    scoring=scoring,\n",
    "    shape_train = X_train_simple.shape,\n",
    "    score_simple_holdout=score_simple_holdout,\n",
    "    score_simple_cv_mean=score_simple_cv_mean,\n",
    "    score_simple_cv_std=score_simple_cv_std,\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "(From now on, we will stop using train/test split but cross-validation on the whole dataset instead)  \n",
    "\n",
    "Let's try to improve performance using the feature `release_date`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Create `X_engineered` by adding a new column `year` to `X`, containing the release year of the track as `integer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù **Let's see how this impact the performance of our model.**\n",
    "- Retrain the same simple linear model on numerical values only, adding the new feature `year`\n",
    "- Save the mean cross-validated performance metric in a variable named `score_engineered` as a `float`\n",
    "- Do not fine tune the model yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Run the following cell to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\"feature_engineering\",\n",
    "    cols = X_engineered.columns,\n",
    "    years = X_engineered.get(\"year\"),\n",
    "    score_engineered=score_engineered\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelining\n",
    "\n",
    "Let's now look for maximum performance by creating a solid preprocessing pipeline.\n",
    "\n",
    "**üìù Create a sklearn preprocessing [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and store it as `preproc`**\n",
    "\n",
    "- Feel free to add any preprocessing steps you think of\n",
    "- You may want to integrate your feature engineering for `year`\n",
    "- You may also further improve it using the `ArtistPopularityTransformer` class given to you below\n",
    "- Don't add any model to it yet\n",
    "\n",
    "üö® Advice: It is better for you to have a working pipeline (even simple one) rather than NO pipeline at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üëâ Do not hesitate to reload a clean new dataset if you need a fresh start.\n",
    "# X = \n",
    "# y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We are giving you below a custom transformer that you may want to use in your pipeline (make sure you understanding it)\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ArtistPopularityTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Compute, as a new feature of the test set, the mean popularity of \n",
    "    all songs made by the artist on the train set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        process artist mean popularity from artists songs popularity\n",
    "        process song global mean popularity\n",
    "        \"\"\"\n",
    "\n",
    "        # process artist popularity\n",
    "        self.artist_popularity = y.groupby(X.artist).agg(\"mean\")\n",
    "        self.artist_popularity.name = \"artist_popularity\"\n",
    "\n",
    "        # process mean popularity\n",
    "        self.mean_popularity = y.mean()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        apply artist mean popularity vs song global mean popularity to songs\n",
    "        \"\"\"\n",
    "\n",
    "        # inject artist popularity\n",
    "        X_copy = X.merge(self.artist_popularity, how=\"left\", left_on=\"artist\", right_index=True)\n",
    "\n",
    "        # fills popularity of unknown artists with song global mean popularity\n",
    "        X_copy.replace(np.nan, self.mean_popularity, inplace=True)\n",
    "\n",
    "        return X_copy[[\"artist_popularity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Store the number of columns/feature after preprocessing your inputs in a variable `col_number`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Run the following cells to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually print your preproc\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your preproc\n",
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\n",
    "    \"preprocessing\",\n",
    "    col_number=col_number,\n",
    "    first_observation = preproc.fit_transform(X, y)[0]\n",
    ").write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "üìù **Time to fine tune your models**\n",
    "\n",
    "- Add an **estimator** to your pipeline (only from Scikit-learn) \n",
    "\n",
    "- Train your pipeline and **fine-tune** (optimize) your estimator to maximize prediction score\n",
    "\n",
    "- You must try to fine tune at least 2 different models: \n",
    "    - create one pipeline with a **linear model** of your choice\n",
    "    - create one pipeline with an **ensemble model** of your choice\n",
    "\n",
    "Then, \n",
    "\n",
    "- Save your two best 5-time cross-validated scores as _float_: `score_linear` and `score_ensemble`\n",
    "\n",
    "- Save your two best trained pipelines as _Pipeline_ objects: `pipe_linear` and `pipe_ensemble`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Run the following cells to save your results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "from sklearn import set_config; set_config(display='diagram')\n",
    "pipe_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print below your best pipe for correction purpose\n",
    "pipe_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "ChallengeResult(\"model_tuning\",\n",
    "    scoring = scoring,\n",
    "    score_linear=score_linear,\n",
    "    score_ensemble=score_ensemble).write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API \n",
    "\n",
    "Time to put a pipeline in production!\n",
    "\n",
    "üëâ Go to https://github.com/lewagon/data-certification-api and follow instructions\n",
    "\n",
    "**This final part is independent from the above notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "lewagon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
